{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d92cfd68-fe34-45e8-a3ba-f885754b9687",
   "metadata": {},
   "source": [
    "# URL Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd53260a-9476-42e6-980e-6f4f08cc7bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import io\n",
    "import gzip\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class GzipUtil:\n",
    "    \"\"\"Utility methods for compressing strings.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def compress_string(s):\n",
    "        buf = io.BytesIO()\n",
    "        with gzip.GzipFile(mode=\"w\", fileobj=buf) as fh:\n",
    "            fh.write(s.encode('utf-8'))\n",
    "        buf.seek(0)\n",
    "        return buf.read()\n",
    "\n",
    "    @staticmethod\n",
    "    def decompress_string(b):\n",
    "        buf = io.BytesIO(b)\n",
    "        with gzip.GzipFile(mode=\"r\", fileobj=buf) as fh:\n",
    "            return fh.read().decode('utf-8')\n",
    "\n",
    "class URLContentCacheSqlite:\n",
    "    \"\"\"Retrieve URL content using a SQLite based cache.\"\"\"\n",
    "    \n",
    "    def __init__(self, db):\n",
    "        self.db = db\n",
    "        self._init_schema()\n",
    "    \n",
    "    def _init_schema(self):\n",
    "        cur = self.db.cursor()\n",
    "        cur.execute(f\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS url_cache (\n",
    "                url VARCHAR(500) NOT NULL,\n",
    "                content BLOB,\n",
    "                content_type VARCHAR(200),\n",
    "                created_date TIMESTAMP NOT NULL\n",
    "            )\n",
    "        \"\"\")\n",
    "\n",
    "        cur.execute(f\"\"\"\n",
    "            CREATE UNIQUE INDEX IF NOT EXISTS i_url_cache_pk ON url_cache (url)\n",
    "        \"\"\")\n",
    "        self.db.commit()\n",
    "    \n",
    "    def get(self, url):\n",
    "        cache_r = self.get_cache(url)\n",
    "        if cache_r is None:\n",
    "            resp = requests.get(url)\n",
    "            if resp.status_code != 200:\n",
    "                raise Exception(f\"Could not download url ({resp.code}) - {url}\")\n",
    "            self.put_cache(url, resp.text, resp.headers['Content-Type'])\n",
    "            cache_r = self.get_cache(url)\n",
    "        return cache_r\n",
    "    \n",
    "    def get_cache(self, url):\n",
    "        cur = self.db.cursor()\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT content, content_type, created_date\n",
    "            FROM url_cache\n",
    "            WHERE url = ?\n",
    "        \"\"\", [url])\n",
    "        results = cur.fetchall()\n",
    "        if len(results) > 0:\n",
    "            r = { col_info[0]: v for col_info, v in zip(cur.description, results[0]) }\n",
    "            r['content'] = GzipUtil.decompress_string(r['content'])\n",
    "            return r\n",
    "\n",
    "    def put_cache(self, url, content, content_type):\n",
    "        cur = self.db.cursor()\n",
    "        cur.execute(f\"\"\"\n",
    "            INSERT INTO url_cache VALUES(?, ?, ?, CURRENT_TIMESTAMP)\n",
    "        \"\"\", [url, GzipUtil.compress_string(content), content_type])\n",
    "        db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c59b0ea-6d2f-46bf-b012-dc49d3e22df6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
